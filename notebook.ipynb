{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
   "metadata": {},
   "source": [
    "![Credit card being held in hand](credit_card.jpg)\n",
    "\n",
    "Commercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n",
    "\n",
    "### The Data\n",
    "\n",
    "The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 40,
    "lastExecutedAt": 1734628792150,
    "lastExecutedByKernel": "8bae85c0-a492-4dab-a0e2-e141b6e00df1",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {
       "quickFilterText": ""
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "0": [
          "b",
          "a",
          "a",
          "b",
          "b"
         ],
         "1": [
          "30.83",
          "58.67",
          "24.50",
          "27.83",
          "20.17"
         ],
         "10": [
          1,
          6,
          0,
          5,
          0
         ],
         "11": [
          "g",
          "g",
          "g",
          "g",
          "s"
         ],
         "12": [
          0,
          560,
          824,
          3,
          0
         ],
         "13": [
          "+",
          "+",
          "+",
          "+",
          "+"
         ],
         "2": [
          0,
          4.46,
          0.5,
          1.54,
          5.625
         ],
         "3": [
          "u",
          "u",
          "u",
          "u",
          "u"
         ],
         "4": [
          "g",
          "g",
          "g",
          "g",
          "g"
         ],
         "5": [
          "w",
          "q",
          "q",
          "w",
          "w"
         ],
         "6": [
          "v",
          "h",
          "h",
          "v",
          "v"
         ],
         "7": [
          1.25,
          3.04,
          1.5,
          3.75,
          1.71
         ],
         "8": [
          "t",
          "t",
          "t",
          "t",
          "t"
         ],
         "9": [
          "t",
          "t",
          "f",
          "t",
          "f"
         ],
         "index": [
          0,
          1,
          2,
          3,
          4
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "0",
           "type": "string"
          },
          {
           "name": "1",
           "type": "string"
          },
          {
           "name": "2",
           "type": "number"
          },
          {
           "name": "3",
           "type": "string"
          },
          {
           "name": "4",
           "type": "string"
          },
          {
           "name": "5",
           "type": "string"
          },
          {
           "name": "6",
           "type": "string"
          },
          {
           "name": "7",
           "type": "number"
          },
          {
           "name": "8",
           "type": "string"
          },
          {
           "name": "9",
           "type": "string"
          },
          {
           "name": "10",
           "type": "integer"
          },
          {
           "name": "11",
           "type": "string"
          },
          {
           "name": "12",
           "type": "integer"
          },
          {
           "name": "13",
           "type": "string"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 5,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>g</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>g</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "449c61bb-97e4-432c-bced-dc757d20235c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1734628792201,
    "lastExecutedByKernel": "8bae85c0-a492-4dab-a0e2-e141b6e00df1",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "cc_apps.info()",
    "outputsMetadata": {
     "0": {
      "height": 458,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    int64  \n",
      " 13  13      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 75.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cc_apps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d1e585f-ca78-4094-904f-e05d384f3ac9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {
       "customFilter": {
        "const": {
         "type": "boolean",
         "valid": true,
         "value": true
        },
        "id": "a8080a2c-2376-44a7-9fe7-fbcb5d6da7da",
        "nodeType": "const"
       },
       "quickFilterText": ""
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "13": [
          383,
          307
         ],
         "index": [
          "-",
          "+"
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "string"
          },
          {
           "name": "13",
           "type": "integer"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 2,
       "truncation_type": null
      },
      "text/plain": [
       "-    383\n",
       "+    307\n",
       "Name: 13, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps[13].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "139f5280-12e8-452a-9793-6b6945720300",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1734628792301,
    "lastExecutedByKernel": "8bae85c0-a492-4dab-a0e2-e141b6e00df1",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "cc_apps[13]= cc_apps[13].replace({'+':1,\n                                 '-':0})"
   },
   "outputs": [],
   "source": [
    "cc_apps[13]= cc_apps[13].replace({'+':1,\n",
    "                                 '-':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "428c80a1-6207-4fcf-9a4e-31de85ce9818",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 218,
    "lastExecutedAt": 1734628792519,
    "lastExecutedByKernel": "8bae85c0-a492-4dab-a0e2-e141b6e00df1",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import numpy as np\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load your dataset (adjust the loading code as per your dataset)\n# Replace '?' with NaN\ncc_apps.replace('?', np.nan, inplace=True)\n\n# Define feature matrix (X) and target vector (y)\nX = cc_apps.drop(13, axis=1)\ny = cc_apps[13]\n\n# Column indices for numeric and categorical columns\nnumeric_features = [1, 2, 7, 10, 12]\ncategorical_features = [0, 3, 4, 5, 6, 8, 9, 11]\n\n# Numerical pipeline\nnumerical_pipeline = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')), \n    ('scaler', StandardScaler())\n])\n\n# Categorical pipeline\ncategorical_pipeline = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')), \n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine pipelines into ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_pipeline, numeric_features),\n        ('cat', categorical_pipeline, categorical_features)\n    ]\n)\n\n# Create full pipeline\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', LogisticRegression())\n])\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the pipeline\npipeline.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = pipeline.predict(X_test)\nbest_score= accuracy_score(y_test, y_pred)\nprint(best_score)",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188405797101449\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset (adjust the loading code as per your dataset)\n",
    "# Replace '?' with NaN\n",
    "cc_apps.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Define feature matrix (X) and target vector (y)\n",
    "X = cc_apps.drop(13, axis=1)\n",
    "y = cc_apps[13]\n",
    "\n",
    "# Column indices for numeric and categorical columns\n",
    "numeric_features = [1, 2, 7, 10, 12]\n",
    "categorical_features = [0, 3, 4, 5, 6, 8, 9, 11]\n",
    "\n",
    "# Numerical pipeline\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine pipelines into ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "best_score= accuracy_score(y_test, y_pred)\n",
    "print(best_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
